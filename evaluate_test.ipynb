{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 380,
   "id": "3ca90934-25ec-4ef4-a880-de928efd8d85",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.ops import nms, box_iou\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "7d3aeee0-f38d-4fae-8b3a-58e3cf1326ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def non_maximum_suppression(pred, iou_threshold=0.5, C=20):\n",
    "    \"\"\"\n",
    "    pred: list of processed yolo output predictions (num boxes, 7)\n",
    "    (max_confidence, x1, y1, x2, y2, max_probability, class_idx)\n",
    "    \"\"\"\n",
    "    nms_boxes = []\n",
    "    \n",
    "    # perform nms on each class independently\n",
    "    for i in range(C):\n",
    "        # get all predicted boxes belonging in this class\n",
    "        boxes = pred[pred[:, -1] == i]\n",
    "        \n",
    "        if boxes.size(0) == 0:\n",
    "            continue\n",
    "        \n",
    "        xyxy = boxes[:, 1:5]\n",
    "        scores = boxes[:, 0]\n",
    "        nms_indices = nms(xyxy, scores, iou_threshold=iou_threshold)\n",
    "        nms_bboxes = boxes[nms_indices]\n",
    "        nms_boxes.append(nms_bboxes)\n",
    "        \n",
    "    nms_boxes = torch.cat(nms_boxes)\n",
    "    return nms_boxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 626,
   "id": "cf0a73da-67ae-4b67-ab89-053f98827b90",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def process_yolo_output(output, \n",
    "                        confidence_threshold=0.5,\n",
    "                        iou_threshold=0.5, S=7, B=2, C=20):\n",
    "    \"\"\"\n",
    "    pred: (N, S, S, 5B+C)\n",
    "    Process output of YOLO\n",
    "    \n",
    "    Returns: N x Boxes x tensor(confidence, x1, y1, x2, y2, probability, class)\n",
    "    \"\"\"\n",
    "    N = output.size(0)\n",
    "    assert output.shape == torch.Size([N, S, S, 5 * B + C])\n",
    "    \n",
    "    processed_output = []\n",
    "    output = output.view(-1, S * S, 5 * B + C)\n",
    "    \n",
    "    for i in range(N):\n",
    "        bboxes = []\n",
    "        for cell_idx in range(S * S):\n",
    "            yolo = output[i][cell_idx] # (5*B+C)\n",
    "            boxes = yolo[:-C]\n",
    "            probabilities = yolo[-C:]\n",
    "            \n",
    "            # select responsible box (box with the highest confidence)\n",
    "            boxes = boxes.view(B, -1)            \n",
    "            confidences = boxes[:, 0]\n",
    "            max_confidence, max_confidence_idx = confidences.max(0) \n",
    "            responsible_box = boxes[max_confidence_idx]\n",
    "            \n",
    "            if max_confidence < confidence_threshold:\n",
    "                continue\n",
    "            \n",
    "            # convert xywh to xyxy\n",
    "            xywh = responsible_box[1:]\n",
    "            gx = cell_idx % S\n",
    "            gy = cell_idx // S\n",
    "            \n",
    "            x = xywh[0]\n",
    "            y = xywh[1]\n",
    "            w = xywh[2]\n",
    "            h = xywh[3]\n",
    "            \n",
    "            x_c = (gx + x) / S\n",
    "            y_c = (gy + y) / S\n",
    "\n",
    "            \n",
    "            x1 = x_c - w / 2\n",
    "            y1 = y_c - h / 2\n",
    "            x2 = x_c + w / 2\n",
    "            y2 = y_c + h / 2\n",
    "            \n",
    "            # get class idx + probability\n",
    "            max_probability, class_idx = probabilities.max(0)\n",
    "            \n",
    "            box = torch.stack([max_confidence, x1, y1, x2, y2, max_probability, class_idx])\n",
    "            box[1:5] = box[1:5].clamp(0, 1) # make sure xys are between 0 and 1\n",
    "            bboxes.append(box)\n",
    "        \n",
    "        bboxes = torch.stack(bboxes)\n",
    "        \n",
    "        # perform NMS on the bboxes\n",
    "        nms_bboxes = non_maximum_suppression(bboxes, iou_threshold=iou_threshold, C=C)    \n",
    "        processed_output.append(nms_bboxes)\n",
    "            \n",
    "    return processed_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "id": "f1ca4431-9b31-4699-808a-b1bb8a34bba2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bboxes(output, \n",
    "               confidence_threshold=0.5,\n",
    "               iou_threshold=0.5,\n",
    "               S=7, B=2, C=20):\n",
    "    \"\"\"\n",
    "    output: SxSx(5B+C)\n",
    "    confidence_threshold: select boxes above this threshold\n",
    "    iou_threshold: nms is applied at this threshold\n",
    "    \"\"\"\n",
    "    bboxes = []\n",
    "    output = output.view(S*S, -1)\n",
    "    \n",
    "    # for each cell, get bounding boxes above confidence threshold\n",
    "    for cell_idx in range(S * S):\n",
    "        # get upper left corner of cell [0, S)\n",
    "        gx = cell_idx % S\n",
    "        gy = cell_idx // S\n",
    "        \n",
    "        cell = output[cell_idx] # (5B + C)\n",
    "        \n",
    "        # get probabilities + localization tensor\n",
    "        probabilities = cell[-C:]\n",
    "        boxes = cell[:-C]\n",
    "        \n",
    "        # get class idx and probability -> select max probability\n",
    "        class_probability, class_idx = probabilities.max(0)\n",
    "        \n",
    "        # get bounding boxes above threshold\n",
    "        boxes = boxes.view(B, -1)\n",
    "        boxes = boxes[boxes[:, 0] >= confidence_threshold]\n",
    "        \n",
    "        # no bounding boxes have predicted confidence above threshold\n",
    "        if len(boxes) == 0:\n",
    "            continue\n",
    "        \n",
    "        # get properties of bounding box\n",
    "        x_c = boxes[:, 1]\n",
    "        y_c = boxes[:, 2]\n",
    "        w = boxes[:, 3]\n",
    "        h = boxes[:, 4]\n",
    "        \n",
    "        # convert to yolo format\n",
    "        x = (gx + x_c) / S\n",
    "        y = (gy + y_c) / S\n",
    "        \n",
    "        x1 = x - w / 2\n",
    "        y1 = y - h / 2\n",
    "        x2 = x + w / 2\n",
    "        y2 = y + h / 2\n",
    "        \n",
    "        # construct bounding box tensor (confidence, x1, y1, x2, y2, class probability, class)\n",
    "        x1y1x2y2 = torch.stack((x1, y1, x2, y2), dim=1).clamp(0, 1)\n",
    "        confidences = boxes[:, 0:1]\n",
    "        num_bboxes = confidences.size(0)\n",
    "        class_probability = class_probability.repeat(num_bboxes, 1)\n",
    "        class_idx = class_idx.repeat(num_bboxes, 1)\n",
    "        bbox = torch.cat((confidences, x1y1x2y2, class_probability, class_idx), dim=1)\n",
    "        bboxes.append(bbox)\n",
    "        \n",
    "    # concat bboxes into one tensor\n",
    "    bboxes = torch.cat(bboxes, dim=0)\n",
    "    \n",
    "    # perform nms on bounding boxes to filter down number of bounding boxes\n",
    "    bboxes = non_maximum_suppression(bboxes, iou_threshold=iou_threshold, C=C)\n",
    "    \n",
    "    return bboxes\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 879,
   "id": "0b233e73-bc4b-4505-b892-92de0c6640a7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0\n",
      "1 0\n",
      "0 1\n",
      "1 1\n",
      "tensor([[0.9000, 0.2000, 0.2000, 0.3000, 0.3000, 0.7000, 1.0000],\n",
      "        [0.8000, 0.7000, 0.2000, 0.8000, 0.3000, 0.9000, 1.0000]])\n"
     ]
    }
   ],
   "source": [
    "pred = torch.tensor([\n",
    "    [[[0.9, 0.5, 0.5, .1, .1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [0.8, 0.5, 0.5, 0.1, 0.1, 0, 0.5, 0.5, 0.1, 0.1, 0.1, 0.9]],\n",
    "     [[0, 0.5, 0.5, 0.1, 0.1, 0, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [0, 0, 0, 1, 1, 0, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7]]]\n",
    "])\n",
    "\n",
    "pred.squeeze_(0)\n",
    "get_bboxes(pred, S=2, B=2, C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 870,
   "id": "a63d16d1-9d4e-4452-be98-b8c3e879b23d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pred = torch.tensor([\n",
    "#     [[[1, 0.5, 0.5, 0.1, 0.1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [1, 0.5, 0.5, 0.1, 0.1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7]],\n",
    "#      [[1, 0.5, 0.5, 0.1, 0.1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [1, 0.5, 0.5, 0.1, 0.1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7]]]\n",
    "# ])\n",
    "\n",
    "pred = torch.tensor([\n",
    "    [[[0.9, 0.5, 0.5, 1, 1, 0.8, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [0.8, 0.5, 0.5, 0.1, 0.1, 0, 0.5, 0.5, 0.1, 0.1, 0.1, 0.9]],\n",
    "     [[0, 0.5, 0.5, 0.1, 0.1, 0, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7], [0, 0, 0, 1, 1, 0, 0.5, 0.5, 0.1, 0.1, 0.3, 0.7]]]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "id": "1c058ecd-6fb6-4e67-a97b-09e74bad2cc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 12])"
      ]
     },
     "execution_count": 871,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 834,
   "id": "30b51806-a013-4297-a6e6-477ba1315327",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[0.9000, 0.0000, 0.0000, 0.7500, 0.7500, 0.7000, 1.0000],\n",
       "         [0.8000, 0.7000, 0.2000, 0.8000, 0.3000, 0.9000, 1.0000]])]"
      ]
     },
     "execution_count": 834,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = process_yolo_output(pred, S=2, B=2, C=2)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 801,
   "id": "89938bdd-6111-4965-ab86-be6f10d98876",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def process_yolo_target(target, S=7, C=20):\n",
    "#     return process_yolo_output(target, S=S, B=1, C=C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "411380c2-410a-47d4-9de4-31582b20d0e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 785,
   "id": "de36cbfe-b5cf-4fdf-aa20-b91d404a6891",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[1.0000, 0.7000, 0.2000, 0.8000, 0.3000, 0.8000, 1.0000],\n",
       "         [1.0000, 0.0000, 0.0000, 0.7500, 0.7500, 0.7000, 1.0000]])]"
      ]
     },
     "execution_count": 785,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = [\n",
    "    torch.tensor([[1.0000, 0.7000, 0.2000, 0.8000, 0.3000, 0.8000, 1.0000],\n",
    "         [1.0000, 0.0000, 0.0000, 0.7500, 0.7500, 0.7000, 1.0000]])\n",
    "]\n",
    "\n",
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f3aa42-a024-48de-9156-de807f8ce8c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 786,
   "id": "9faae0a1-25db-4ac8-9bf5-8b565311ecd5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def average_precision(pred, target, c, iou_threshold=0.5):\n",
    "    # number of targets\n",
    "    TP_FN = 0\n",
    "    N = len(pred)\n",
    "    TP_FP = [] # will be condensed to one-hot vector\n",
    "    scores = [] # corresponding score for each TP_FN label\n",
    "    \n",
    "    # for each image, label predictions as TP or FP (store in a one-hot vector 1=TP, 0=FP)\n",
    "    for i in range(N):\n",
    "        pred_boxes = pred[i]\n",
    "        target_boxes = target[i]\n",
    "        \n",
    "        # get boxes classified in the specified class\n",
    "        pred_boxes = pred_boxes[pred_boxes[:, -1] == c]\n",
    "        target_boxes = target_boxes[target_boxes[:, -1] == c]\n",
    "        \n",
    "        # continue if TP_FN for this image is 0\n",
    "        if len(target_boxes) == 0:\n",
    "            continue\n",
    "        \n",
    "        num_TP_FN = target_boxes.size(0)\n",
    "        num_TP_FP = pred_boxes.size(0)\n",
    "        TP_FP_vec = torch.zeros(num_TP_FP)\n",
    "\n",
    "        # number of target boxes = TP_FN\n",
    "        TP_FN += num_TP_FN\n",
    "\n",
    "        # calculate pairwise IOU between predicted boxes and target boxes -> highest IOU above threshold gets classified\n",
    "        # as TP, duplicate bounding boxes + boxes below IOU threshold are classified as FP\n",
    "        pred_x1y1x2y2 = pred_boxes[:, 1:5]\n",
    "        target_x1y1x2y2 = target_boxes[:, 1:5]\n",
    "        \n",
    "        ious = box_iou(target_x1y1x2y2, pred_x1y1x2y2)        \n",
    "        max_ious, max_iou_indices = ious.max(dim=1)        \n",
    "        for max_iou, max_iou_idx in zip(max_ious, max_iou_indices):\n",
    "            # this is the best bounding box for each target, label TP if it is above IOU threshold,\n",
    "            # rest of bounding boxes are duplicates\n",
    "            if max_iou >= iou_threshold:\n",
    "                TP_FP_vec[max_iou_idx] = 1\n",
    "        \n",
    "        # get scores for each bounding box\n",
    "        confidences = pred_boxes[:, 0]\n",
    "        \n",
    "        # append TP_FP and scores\n",
    "        TP_FP.append(TP_FP_vec)\n",
    "        scores.append(confidences)\n",
    "    \n",
    "    # no targets; AP = 0\n",
    "    if len(TP_FP) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # condense TP_FP and scores into one vector\n",
    "    TP_FP = torch.cat(TP_FP)\n",
    "    scores = torch.cat(scores)\n",
    "    \n",
    "    # sort by score\n",
    "    _, sorted_score_indices = scores.sort(descending=True)\n",
    "    TP_FP = TP_FP[sorted_score_indices]\n",
    "    \n",
    "    # get cumulative TPs\n",
    "    TP = torch.cumsum(TP_FP, dim=0)\n",
    "    \n",
    "    # calculate precision and recall\n",
    "    # precision = TP / (TP + FP) (predictions), recall = TP / (TP + FN) (ground truths)\n",
    "    # P = torch.cumsum(torch.ones_like(TP), dim=0)\n",
    "    P = torch.arange(1, TP.size(0) + 1)\n",
    "    \n",
    "    precision = TP / P\n",
    "    recall = TP / TP_FN\n",
    "    \n",
    "    # add 1 in front of precision and 0 in front of recall\n",
    "    precision = torch.cat((torch.tensor([1]), precision))\n",
    "    recall = torch.cat((torch.tensor([0]), recall))\n",
    "    \n",
    "    # area under PR-curve\n",
    "    auc = torch.trapezoid(precision, recall)\n",
    "    \n",
    "    return auc.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 787,
   "id": "50b23cbc-5d9b-4cb1-8daa-b1bbe111aa68",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_average_precision(pred, target, iou_threshold=0.5, C=20):\n",
    "    \"\"\"\n",
    "    pred, target: N x bounding boxes x 7\n",
    "    \"\"\"\n",
    "    assert len(pred) == len(target)\n",
    "        \n",
    "    total_ap = 0\n",
    "    \n",
    "    # for each class, calculate the average precision (AUC of PR curve)\n",
    "    for i in range(C):\n",
    "        print(i)\n",
    "        ap = average_precision(pred, target, iou_threshold=iou_threshold, c=i)\n",
    "        print(ap)\n",
    "        total_ap += ap\n",
    "    \n",
    "    # compute the mean of the APs\n",
    "    mAP = total_ap / C\n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 788,
   "id": "f7897bb0-8c3d-4a73-a707-9e22b20bf90e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 788,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(pred, target, C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 789,
   "id": "4b67f2f3-3c10-4fd5-90e9-212ddf9fbf5d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def mean_average_precision(pred, target, iou_threshold=0.5, C=20):\n",
    "    \"\"\"\n",
    "    pred, target: N x bounding boxes x 7\n",
    "    \"\"\"\n",
    "    assert len(pred) == len(target)\n",
    "    \n",
    "    \n",
    "    print(pred, target)\n",
    "    aps = []\n",
    "    \n",
    "    for i in range(C):\n",
    "        # find all boxes target is in the current class\n",
    "        print(i)\n",
    "        ground_truths = 0\n",
    "        labels = []\n",
    "        scores = []\n",
    "        \n",
    "        for j in range(len(pred)):\n",
    "            pred_bboxes = pred[j]\n",
    "            target_bboxes = target[j]\n",
    "            \n",
    "            pred_bboxes = pred_bboxes[pred_bboxes[:, -1] == i]\n",
    "            target_bboxes = target_bboxes[target_bboxes[:, -1] == i]\n",
    "            \n",
    "            ground_truths += len(target_bboxes)\n",
    "            \n",
    "            if pred_bboxes.size(0) == 0:\n",
    "                continue\n",
    "                \n",
    "            print(pred_bboxes[:, 1:5], target_bboxes[:, 1:5])\n",
    "            \n",
    "            tpfp_labels = torch.zeros(pred_bboxes.size(0))\n",
    "            ious = box_iou(pred_bboxes[:, 1:5], target_bboxes[:, 1:5])\n",
    "            max_ious, max_ious_indices = ious.max(0)\n",
    "            \n",
    "            print(\"max ious\")\n",
    "            print(ious)\n",
    "            print(max_ious, max_ious_indices)\n",
    "            print(tpfp_labels)\n",
    "            \n",
    "            # maybe there's a mistake here!\n",
    "            for max_iou, max_iou_idx in zip(max_ious, max_ious_indices):\n",
    "                if max_iou >= iou_threshold:\n",
    "                    print(max_iou_idx)\n",
    "                    tpfp_labels[max_iou_idx] = 1\n",
    "            \n",
    "            print(tpfp_labels)\n",
    "            \n",
    "            labels.append(tpfp_labels)\n",
    "            score = pred_bboxes[:, 0]\n",
    "            scores.append(score)\n",
    "        \n",
    "        if len(labels) == 0:\n",
    "            aps.append(0)\n",
    "            continue\n",
    "            \n",
    "        labels = torch.cat(labels)\n",
    "        scores = torch.cat(scores)\n",
    "        \n",
    "        print(\"scores labels\")\n",
    "        print(labels, scores)\n",
    "        \n",
    "        # sort by confidence\n",
    "        sorted_scores, scores_indices = scores.sort()\n",
    "        print(sorted_scores, scores_indices)\n",
    "        \n",
    "        labels = labels[scores_indices]\n",
    "        \n",
    "        print(labels)\n",
    "        \n",
    "        TPs = torch.cumsum(labels, dim=0)\n",
    "        rolling_predicted = torch.cumsum(torch.ones(len(TPs)), dim=0)\n",
    "        recall = labels / ground_truths\n",
    "        precision = TPs / rolling_predicted\n",
    "        \n",
    "        print(precision, recall)\n",
    "        \n",
    "        precision = torch.cat((torch.tensor([1]), precision))\n",
    "        recall = torch.cat((torch.tensor([0]), recall))\n",
    "        \n",
    "        print(precision, recall)\n",
    "        \n",
    "        ap = torch.trapezoid(precision, recall)\n",
    "        \n",
    "        print(\"ap\")\n",
    "        print(ap)\n",
    "        \n",
    "        aps.append(ap.item())\n",
    "        \n",
    "    mean_ap = sum(aps) / len(aps)\n",
    "    \n",
    "    return mean_ap\n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 790,
   "id": "0cd5de4f-9e23-447d-8281-44734584e2d1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[0.9000, 0.0000, 0.0000, 0.7500, 0.7500, 0.7000, 1.0000],\n",
      "        [0.8000, 0.7000, 0.2000, 0.8000, 0.3000, 0.9000, 1.0000]])] [tensor([[1.0000, 0.7000, 0.2000, 0.8000, 0.3000, 0.8000, 1.0000],\n",
      "        [1.0000, 0.0000, 0.0000, 0.7500, 0.7500, 0.7000, 1.0000]])]\n",
      "0\n",
      "1\n",
      "tensor([[0.0000, 0.0000, 0.7500, 0.7500],\n",
      "        [0.7000, 0.2000, 0.8000, 0.3000]]) tensor([[0.7000, 0.2000, 0.8000, 0.3000],\n",
      "        [0.0000, 0.0000, 0.7500, 0.7500]])\n",
      "max ious\n",
      "tensor([[0.0088, 1.0000],\n",
      "        [1.0000, 0.0088]])\n",
      "tensor([1., 1.]) tensor([1, 0])\n",
      "tensor([0., 0.])\n",
      "tensor(1)\n",
      "tensor(0)\n",
      "tensor([1., 1.])\n",
      "scores labels\n",
      "tensor([1., 1.]) tensor([0.9000, 0.8000])\n",
      "tensor([0.8000, 0.9000]) tensor([1, 0])\n",
      "tensor([1., 1.])\n",
      "tensor([1., 1.]) tensor([0.5000, 0.5000])\n",
      "tensor([1., 1., 1.]) tensor([0.0000, 0.5000, 0.5000])\n",
      "ap\n",
      "tensor(0.5000)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.25"
      ]
     },
     "execution_count": 790,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_average_precision(pred, target, C=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 791,
   "id": "236642b1-8f7a-4711-8746-c4bb6d46dd27",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# this result above is incorrect! -> should be 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "id": "582cd4b2-cc7d-4d27-acf9-5363d5a0d710",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6]])"
      ]
     },
     "execution_count": 760,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([[1, 2, 3,], \n",
    "                  [4, 5, 6]])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 761,
   "id": "f7b8a745-47b3-4ca9-bc16-6650f040bab9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.max(\n",
       "values=tensor([3, 6]),\n",
       "indices=tensor([2, 2]))"
      ]
     },
     "execution_count": 761,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.max(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f4716a-687d-4f4d-979e-8513f36d94e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
