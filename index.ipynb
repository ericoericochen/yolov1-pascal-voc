{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1f08891c-29e2-430f-882c-3d6c0f0eb1a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "afc3e00b-aa61-494e-a841-1403c91ad8e1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.optim.lr_scheduler import MultiStepLR, StepLR, ExponentialLR\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "import dataset\n",
    "from model import ResNet18YOLOv1\n",
    "from loss import YOLOv1Loss\n",
    "from tqdm import tqdm\n",
    "from evaluate import get_bboxes, mean_average_precision"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6ab21d-6f8d-485c-994d-8f603994f0ae",
   "metadata": {},
   "source": [
    "# About\n",
    "This is an implementation of YOLOv1 from ***You Only Look Once: Unified, Real-Time Object Detection by Joseph Redmon, Santosh Divvala, Ross Girshick, and Ali Firhadi.*** Object detection is figuring out what objects are in an image and where they are. Another way to look at this problem is how can we write a computer program that draws bounding boxes around objects and predicts what kind of objects they are. YOLO solves this problem and does it super fast, like state of the art fast! I made slight modifications to the architecture and loss function which I'll discuss further down.\n",
    "\n",
    "Let's talk about R-CNN, the predecessor to YOLO. It proposed regions, ran a classifier on every region, and did some post-processing to produce the final result. In simple language this translates to:\n",
    "1. Lemme draw a lot of bounding boxes where I think objects are\n",
    "2. Lemme figure out what are in the bounding boxes I drew\n",
    "3. Ok, I drew too many bounding boxes, lemme remove most of them and keep the important ones\n",
    "\n",
    "This is a lot of steps. What YOLO does instead is ***unified detection***. Unified detection combines the different components of object detection (where are the objects and what kind of objects are they) into one Convolutional Neural Network. You give it an image and in one swoop, it tells you exactly that.\n",
    "\n",
    "Here's how it does it:\n",
    "1. Divide the image into a SxS grid\n",
    "2. Each cell in the grid predicts B bounding boxes and C class probabilities (what it thinks the object is)\n",
    "\n",
    "We represent bounding boxes with 5 numbers: x, y, w, h, p.\n",
    "- (x, y): center of the bounding box\n",
    "- w: width\n",
    "- h: height\n",
    "- p: confidence (a measure of how confident we are that this box captures an object and matches the ground truth)\n",
    "\n",
    "Accordingly, YOLOv1 produces a SxSx(5B+C) tensor. Each cell predicts B bounding boxes, how do we choose which one is the \"true\" predictor? How do we measure how good our bounding box and classification predictions are? \n",
    "\n",
    "We check which bounding box has the greatest overlap (IOU: Intersection Over Union) with the ground truth and choose that one as a predictor. We use this loss function to measure the \"goodness\" of our predictions:\n",
    "\n",
    "![yolo loss function](https://i.stack.imgur.com/IddFu.png)\n",
    "\n",
    "On a high level, it is the squared error between our prediction and the ground truth. Let's start training!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df0990c1-443d-4ef6-815b-85219f362da7",
   "metadata": {},
   "source": [
    "# Data (PASCAL VOC 2007)\n",
    "PASCAL VOC Detection Dataset contains annotated images with 20 labelled classes and bounding boxes. There are 2,501 images in the training set, 2,510 images in the validation set, and 4,952 images in the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9426d062-f1ea-4666-9828-555238cce5db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# original dataset\n",
    "pascal_voc_train = torchvision.datasets.VOCDetection(\n",
    "    root=\"data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"train\",\n",
    "    download=False\n",
    ")\n",
    "\n",
    "pascal_voc_val = torchvision.datasets.VOCDetection(\n",
    "    root=\"data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"val\",\n",
    "    download=False\n",
    ")\n",
    "\n",
    "pascal_voc_test = torchvision.datasets.VOCDetection(\n",
    "    root=\"data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"test\",\n",
    "    download=False\n",
    ")\n",
    "\n",
    "# resize to 448x448, normalize, and convert annotations to target tensors\n",
    "voc_train = dataset.PascalVOC(pascal_voc=pascal_voc_train)\n",
    "voc_val = dataset.PascalVOC(pascal_voc=pascal_voc_val)\n",
    "voc_test = dataset.PascalVOC(pascal_voc=pascal_voc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dff579e9-dc2d-42ab-9941-fbfa7aad7c05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# dataloaders\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "train_loader = DataLoader(voc_train, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(voc_val, batch_size=BATCH_SIZE, shuffle=False)\n",
    "test_loader = DataLoader(voc_test, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b19bf5ea-e1a5-4c45-883b-5fb57eb7de42",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 448, 448]) torch.Size([64, 7, 7, 25])\n"
     ]
    }
   ],
   "source": [
    "for x, y in train_loader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd349501-c0d8-4f17-b193-aa5e46958439",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c0779b53-46a7-4e7a-9e72-e335c5a70cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = \"cpu\"\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device(\"cuda\")\n",
    "if torch.backends.mps.is_available() and torch.backends.mps.is_built():\n",
    "    DEVICE = torch.device(\"mps\")\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "165ccdf4-9c4d-4a3c-a070-70d8d38dc370",
   "metadata": {},
   "source": [
    "# Hyperparameters\n",
    "- S: dimensions of SxS grid\n",
    "- B: number of bounding boxes predicted per cell\n",
    "- C: number of classes\n",
    "- lambda_coord: penalty on incorrect localization loss\n",
    "- lambda_noobj: penalty on incorrect noobj confidence loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acc9e47e-6e57-46e5-8c03-b533c891426c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = 7\n",
    "B = 2\n",
    "C = 20\n",
    "lambda_coord = 5.0\n",
    "lambda_noobj = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bec5d95-0199-4552-95c7-4b6d97980fc4",
   "metadata": {},
   "source": [
    "# Training Setup\n",
    "Model, loss function, optimizer, scheduler and evaluation utils\n",
    "\n",
    "- Model: ResNet18 convolutional layers pretrained on ImageNet with 2 feedforward layers outputting a (N x S x S x (5B + C)) tensor\n",
    "- Loss: Squared Error Loss\n",
    "- Optimizer + Scheduler: Stochastic Gradient Descent with momentum of 0.9 and weight decay of 0.0005. We train with learning rate set to 1e-3 for the first 75 epochs, 1e-4 for the next 30 epochs, and 1e-5 for the final 30 epochs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ba24ea55-5d84-4847-9304-e39e5417c712",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "yolo = ResNet18YOLOv1(S=S, B=B, C=C).to(DEVICE)\n",
    "yolo_loss = YOLOv1Loss(S=S, B=B, C=C, lambda_coord=lambda_coord, lambda_noobj=lambda_noobj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3d7944b6-02d3-4492-be2b-c9c9d4d5db41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "MOMENTUM = 0.9\n",
    "WEIGHT_DECAY = 0.0005\n",
    "PRE_LEARNING_RATE = 1e-4\n",
    "LEARNING_RATE = 1e-3\n",
    "PRE_EPOCHS = 5\n",
    "EPOCHS = 135\n",
    "\n",
    "optimizer = torch.optim.SGD(yolo.parameters(), lr=PRE_LEARNING_RATE, momentum=MOMENTUM, weight_decay=WEIGHT_DECAY)\n",
    "pre_exp_factor = (LEARNING_RATE / PRE_LEARNING_RATE) ** (1 / PRE_EPOCHS)\n",
    "pre_scheduler = ExponentialLR(optimizer, gamma=pre_exp_factor)\n",
    "scheduler = MultiStepLR(optimizer, milestones=[75, 105], gamma=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55178899-b207-43a0-b351-d8508b46a2f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Evaluating Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "762600af-25e1-4a7a-af61-a2914c892db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_loss(model, criterion, dataloader):\n",
    "    total_loss = 0\n",
    "    model.eval()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X = X.to(DEVICE)\n",
    "            Y = Y.to(DEVICE)\n",
    "\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "            total_loss += loss.item()\n",
    "            break\n",
    "            \n",
    "    N = len(dataloader)\n",
    "    # loss = total_loss / N\n",
    "    loss = total_loss\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fadd2fd-d7b5-467a-913d-84a7442e1e22",
   "metadata": {},
   "source": [
    "## Evaluating mAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "50f98021-62a9-4213-b921-ab77362527ae",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "CONFIDENCE_THRESHOLD = 0.25\n",
    "IOU_THRESHOLD = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3a01196e-993e-40a4-97e9-04d9c471aca0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def bboxes(model, dataloader):\n",
    "    model.eval()\n",
    "    pred_bboxes = []\n",
    "    target_bboxes = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for X, Y in dataloader:\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "            \n",
    "            for i in range(len(X)):\n",
    "                x = pred[i]\n",
    "                y = Y[i]\n",
    "                \n",
    "                pred_bbox = get_bboxes(x, confidence_threshold=CONFIDENCE_THRESHOLD, iou_threshold=IOU_THRESHOLD, S=S, B=B, C=C)\n",
    "                target_bbox = get_bboxes(y, confidence_threshold=CONFIDENCE_THRESHOLD, iou_threshold=IOU_THRESHOLD, S=S, B=1, C=C)\n",
    "                \n",
    "                pred_bboxes.append(pred_bbox)\n",
    "                target_bboxes.append(target_bbox)\n",
    "    \n",
    "    return pred_bboxes, target_bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dc8fec1a-683f-45b7-82d9-cb0aac3ffedb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_mAP(model, dataloader):\n",
    "    pred_bboxes, target_bboxes = bboxes(model, dataloader)\n",
    "    mAP = mean_average_precision(pred_bboxes, target_bboxes, iou_threshold=IOU_THRESHOLD, C=C)\n",
    "    \n",
    "    return mAP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b524fa7b-cbca-43af-8efd-c6334c553433",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5430c9cb-2383-4030-b7c5-3e561e51aa3d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1dc6eb43-0652-4fc0-8d22-f7720c24bc7a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train(model, criterion, train_loader, val_loader, optimizer, scheduler, pre_scheduler, pre_epochs, epochs):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    best_val_loss = float(\"inf\")\n",
    "    active_scheduler = pre_scheduler\n",
    "    \n",
    "    N = len(train_loader)\n",
    "    \n",
    "    for epoch in range(pre_epochs + epochs):\n",
    "        # set to train mode\n",
    "        model.train()\n",
    "        total_loss = 0\n",
    "        \n",
    "        lr = optimizer.param_groups[0][\"lr\"]\n",
    "        pbar = tqdm(train_loader, leave=False, desc=f\"Epoch [{epoch+1}/{pre_epochs + epochs}]: lr={lr}\")\n",
    "        \n",
    "        for i, (X, Y) in enumerate(pbar):\n",
    "            X, Y = X.to(DEVICE), Y.to(DEVICE)\n",
    "            pred = model(X)\n",
    "            loss = criterion(pred, Y)\n",
    "            train_losses.append(loss.item())\n",
    "            total_loss += loss.item()\n",
    "            # val_loss = compute_loss(model, criterion, val_loader)\n",
    "            # val_losses.append(val_loss)\n",
    "            \n",
    "            # backprop\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # update progress bar\n",
    "            pbar.set_postfix(batch_loss=loss.item())\n",
    "        \n",
    "        # update learning rate with scheduler\n",
    "        active_scheduler.step()  \n",
    "        \n",
    "        # calculate metrics\n",
    "        train_loss = total_loss / N\n",
    "        val_loss = compute_loss(model, criterion, val_loader)\n",
    "        \n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            # save best model\n",
    "            print(\"=> saving model\")\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "        \n",
    "        if epoch == pre_epochs - 1:\n",
    "            active_scheduler = scheduler\n",
    "        \n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}]: Loss={train_loss}, Val Loss={val_loss}\")\n",
    "    \n",
    "    return {\n",
    "        \"train_losses\": train_losses,\n",
    "        \"val_losses\": val_losses,\n",
    "        \"pre_epochs\": pre_epochs,\n",
    "        \"epochs\": epochs\n",
    "    }\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "822011ce-19f5-4497-9efb-bc465004e0fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [1/135]: Loss=18.438377451896667, Val Loss=6.989580154418945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [2/135]: Loss=8.007345354557037, Val Loss=5.3820953369140625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [3/135]: Loss=6.713325822353363, Val Loss=5.198844909667969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [4/135]: Loss=6.016474312543869, Val Loss=5.052807807922363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [5/135]: Loss=5.434785181283951, Val Loss=4.992927551269531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [6/135]: Loss=4.875706040859223, Val Loss=4.884123802185059\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [7/135]: Loss=4.21184828877449, Val Loss=4.815620422363281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [8/135]: Loss=3.8218248069286345, Val Loss=4.735628128051758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/135]: Loss=3.4411068379879, Val Loss=4.891972541809082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/135]: Loss=3.1556669950485228, Val Loss=4.972096920013428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/135]: Loss=3.030849117040634, Val Loss=4.87185525894165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/135]: Loss=2.7462028205394744, Val Loss=4.743162631988525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [13/135]: Loss=2.559248313307762, Val Loss=4.699849605560303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [14/135]: Loss=2.365251213312149, Val Loss=4.554368019104004\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [15/135]: Loss=2.217328372597694, Val Loss=4.534677982330322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/135]: Loss=2.129265856742859, Val Loss=4.605022430419922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/135]: Loss=2.0250596582889555, Val Loss=4.616058826446533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/135]: Loss=1.9047053337097168, Val Loss=4.643465042114258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/135]: Loss=1.8305783420801163, Val Loss=4.63784122467041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/135]: Loss=1.7734659790992737, Val Loss=4.582029342651367\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/135]: Loss=1.697898694872856, Val Loss=4.712367057800293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/135]: Loss=1.6990468353033066, Val Loss=4.88136625289917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/135]: Loss=1.7102133721113204, Val Loss=4.799613952636719\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/135]: Loss=1.6193825393915176, Val Loss=4.661437034606934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/135]: Loss=1.5192356407642365, Val Loss=4.717012405395508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/135]: Loss=1.5209031015634538, Val Loss=4.58297061920166\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/135]: Loss=1.4396533459424972, Val Loss=4.7719526290893555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/135]: Loss=1.3692256718873979, Val Loss=4.725193023681641\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/135]: Loss=1.2999969244003295, Val Loss=4.629217147827148\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [30/135]: Loss=1.2728725776076317, Val Loss=4.513859272003174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [31/135]: Loss=1.2516739875078202, Val Loss=4.5059099197387695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [32/135]: Loss=1.2544240176677703, Val Loss=4.470510482788086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/135]: Loss=1.2463082030415535, Val Loss=4.544309616088867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/135]: Loss=1.2328982591629027, Val Loss=4.526529312133789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/135]: Loss=1.1947389557957648, Val Loss=4.575481414794922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [36/135]: Loss=1.1573955044150352, Val Loss=4.42613410949707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [37/135]: Loss=1.0422888562083243, Val Loss=4.385383605957031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [38/135]: Loss=1.0121290519833566, Val Loss=4.380411148071289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/135]: Loss=0.9902253568172454, Val Loss=4.3873610496521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/135]: Loss=0.9798985123634338, Val Loss=4.3965888023376465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/135]: Loss=0.9556765392422676, Val Loss=4.386624336242676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [42/135]: Loss=0.9503527671098709, Val Loss=4.374203681945801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/135]: Loss=0.9327093988656998, Val Loss=4.394341468811035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/135]: Loss=0.9262596666812897, Val Loss=4.385965347290039\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/135]: Loss=0.9012362152338028, Val Loss=4.388501167297363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/135]: Loss=0.9161386415362358, Val Loss=4.387277126312256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/135]: Loss=0.9028321355581284, Val Loss=4.3760666847229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [48/135]: Loss=0.8938896223902703, Val Loss=4.365889549255371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [49/135]: Loss=0.8903761774301528, Val Loss=4.364752769470215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/135]: Loss=0.8766697153449059, Val Loss=4.378524303436279\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [51/135]: Loss=0.8657611012458801, Val Loss=4.351946830749512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/135]: Loss=0.8627159699797631, Val Loss=4.382003307342529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/135]: Loss=0.8674574047327042, Val Loss=4.364062786102295\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/135]: Loss=0.856218321621418, Val Loss=4.377956867218018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/135]: Loss=0.8415544688701629, Val Loss=4.395225524902344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/135]: Loss=0.8417152047157288, Val Loss=4.392341136932373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/135]: Loss=0.8397885590791703, Val Loss=4.370244026184082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/135]: Loss=0.8337332144379616, Val Loss=4.377070426940918\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/135]: Loss=0.8340521842241287, Val Loss=4.353064060211182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [60/135]: Loss=0.8205058261752128, Val Loss=4.332716464996338\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/135]: Loss=0.8144300445914269, Val Loss=4.3733673095703125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/135]: Loss=0.8234325975179673, Val Loss=4.332716941833496\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [63/135]: Loss=0.8220765084028244, Val Loss=4.330210208892822\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/135]: Loss=0.8050012469291687, Val Loss=4.3347601890563965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> saving model\n",
      "Epoch [65/135]: Loss=0.8122555375099182, Val Loss=4.328667640686035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/135]: Loss=0.7992564469575882, Val Loss=4.329145431518555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/135]: Loss=0.80242008715868, Val Loss=4.329507827758789\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/135]: Loss=0.8084523305296898, Val Loss=4.329780101776123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/135]: Loss=0.8069570437073708, Val Loss=4.329713821411133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/135]: Loss=0.7978807762265205, Val Loss=4.331157684326172\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                           \r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train_result \u001b[38;5;241m=\u001b[39m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43myolo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m      \u001b[49m\u001b[43myolo_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m      \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m      \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m      \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpre_scheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpre_scheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m      \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m      \u001b[49m\u001b[43mpre_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPRE_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m      \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mEPOCHS\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[30], line 17\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(model, criterion, train_loader, val_loader, optimizer, scheduler, pre_scheduler, pre_epochs, epochs)\u001b[0m\n\u001b[1;32m     14\u001b[0m lr \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mparam_groups[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlr\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m pbar \u001b[38;5;241m=\u001b[39m tqdm(train_loader, leave\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpre_epochs\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39mepochs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]: lr=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, (X, Y) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pbar):\n\u001b[1;32m     18\u001b[0m     X, Y \u001b[38;5;241m=\u001b[39m X\u001b[38;5;241m.\u001b[39mto(DEVICE), Y\u001b[38;5;241m.\u001b[39mto(DEVICE)\n\u001b[1;32m     19\u001b[0m     pred \u001b[38;5;241m=\u001b[39m model(X)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/tqdm/std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1177\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m obj \u001b[38;5;129;01min\u001b[39;00m iterable:\n\u001b[1;32m   1179\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m obj\n\u001b[1;32m   1180\u001b[0m         \u001b[38;5;66;03m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1181\u001b[0m         \u001b[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/torch/utils/data/dataloader.py:633\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    632\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 633\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    635\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    636\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    637\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/torch/utils/data/dataloader.py:677\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    676\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 677\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    678\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    679\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m~/sagemaker-studiolab-notebooks/yolov1-pascal-voc/dataset.py:150\u001b[0m, in \u001b[0;36mPascalVOC.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index):\n\u001b[0;32m--> 150\u001b[0m     image, annotation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    152\u001b[0m     \u001b[38;5;66;03m# transform image and annotation\u001b[39;00m\n\u001b[1;32m    153\u001b[0m     image \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransform(image)\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/torchvision/datasets/voc.py:200\u001b[0m, in \u001b[0;36mVOCDetection.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, index: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, Any]:\n\u001b[1;32m    193\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[38;5;124;03m        index (int): Index\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[38;5;124;03m        tuple: (image, target) where target is a dictionary of the XML tree.\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mRGB\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    201\u001b[0m     target \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparse_voc_xml(ET_parse(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mannotations[index])\u001b[38;5;241m.\u001b[39mgetroot())\n\u001b[1;32m    203\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtransforms \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/PIL/Image.py:911\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    863\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;28mself\u001b[39m, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, matrix\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, dither\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, palette\u001b[38;5;241m=\u001b[39mPalette\u001b[38;5;241m.\u001b[39mWEB, colors\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m256\u001b[39m\n\u001b[1;32m    865\u001b[0m ):\n\u001b[1;32m    866\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 911\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    913\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    914\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    915\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/deeplearning/lib/python3.9/site-packages/PIL/ImageFile.py:269\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    268\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 269\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    271\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_result = train(yolo, \n",
    "      yolo_loss, \n",
    "      train_loader=train_loader, \n",
    "      val_loader=val_loader, \n",
    "      optimizer=optimizer, \n",
    "      pre_scheduler=pre_scheduler,\n",
    "      scheduler=scheduler,\n",
    "      pre_epochs=PRE_EPOCHS,\n",
    "      epochs=EPOCHS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cd14f5cd-d313-4de5-9035-22fead0a7930",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'train_losses': [0.8605380043387413,\n",
       "  0.8637479037046433,\n",
       "  0.8546822085976601,\n",
       "  0.8509144648909569,\n",
       "  0.8564467936754226,\n",
       "  0.8534302830696106,\n",
       "  0.8544076174497605,\n",
       "  0.850600641965866,\n",
       "  0.8588794693350792,\n",
       "  0.8570745304226876,\n",
       "  0.8504234209656716,\n",
       "  0.8501313015818596,\n",
       "  0.8508121773600579,\n",
       "  0.8593935877084732,\n",
       "  0.8524240866303444,\n",
       "  0.8544886112213135,\n",
       "  0.849775955080986,\n",
       "  0.8467658802866935,\n",
       "  0.8504383265972137,\n",
       "  0.8455603152513504,\n",
       "  0.8545303136110306,\n",
       "  0.8436845406889916,\n",
       "  0.8530150756239891,\n",
       "  0.8486282780766488,\n",
       "  0.8435310542583465,\n",
       "  0.8553196310997009,\n",
       "  0.8475099980831147,\n",
       "  0.836984796822071,\n",
       "  0.8407960385084152,\n",
       "  0.8525115951895714],\n",
       " 'val_losses': [4.38873815536499,\n",
       "  4.387818813323975,\n",
       "  4.388105869293213,\n",
       "  4.387928009033203,\n",
       "  4.388128757476807,\n",
       "  4.389425754547119,\n",
       "  4.3873491287231445,\n",
       "  4.3884382247924805,\n",
       "  4.388421058654785,\n",
       "  4.386437892913818,\n",
       "  4.385745048522949,\n",
       "  4.385434150695801,\n",
       "  4.385828018188477,\n",
       "  4.385298728942871,\n",
       "  4.3854475021362305,\n",
       "  4.386116981506348,\n",
       "  4.385022163391113,\n",
       "  4.383125305175781,\n",
       "  4.382594108581543,\n",
       "  4.384244918823242,\n",
       "  4.384769916534424,\n",
       "  4.383597373962402,\n",
       "  4.382791042327881,\n",
       "  4.381626129150391,\n",
       "  4.379391193389893,\n",
       "  4.38040828704834,\n",
       "  4.381540298461914,\n",
       "  4.382408618927002,\n",
       "  4.394086837768555,\n",
       "  4.393765926361084],\n",
       " 'epochs': 30}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29cfe04e-75ac-4fff-b0fc-d91d7fca882b",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "18e5ef2f-7216-4db9-a300-1729fc8d5e02",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15139479707577266"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mAP(yolo, val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d98e5057-2e6a-4614-b028-ed2c737c8e43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5534197650849819"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_mAP(yolo, train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e95b72-a060-4c84-9e19-747f8528dc5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning:Python",
   "language": "python",
   "name": "conda-env-deeplearning-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
