{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3655f03-1494-4678-9885-3e859882b97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "45d56b55-2a11-491f-b173-4deaf2a31472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataset\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9c8d69-fdcb-4cf5-8db6-954801fb9d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pascal_voc_train = torchvision.datasets.VOCDetection(\n",
    "    root=\"../data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"train\",\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15f266e-7ac2-4b57-8e3f-146886742030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMING PASCAL VOC\n"
     ]
    }
   ],
   "source": [
    "voc_train = dataset.PascalVOC(pascal_voc=pascal_voc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "70f22340-8e61-4875-8f02-d13102365e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "864f6c31-62c8-40fc-b00f-4767443189d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YOLOv1Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLOv1 Loss\n",
    "    \"\"\"\n",
    "    def __init__(self, S=7, B=2, C=20, lambda_coord=5, lambda_noobj=0.5):\n",
    "        \"\"\"\n",
    "        S: dimension of the S x S grid\n",
    "        B: number of bounding boxes predicted by network\n",
    "        C: number of classes\n",
    "        lambda_coord: penalty for coord loss\n",
    "        lambda_noobj: penalty for confidence loss when no object is present in target\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        \n",
    "    def _iou(self, pred, target):\n",
    "        pass\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred: (N x S x S x (5 * B + C))\n",
    "        target: (N x S x S x (5 + C))\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"YOLO LOSS\")\n",
    "        \n",
    "        # check pred and target are in the correct shape\n",
    "        assert len(pred) == len(target)\n",
    "        N = len(pred)\n",
    "        \n",
    "        # get parameters of YOLO loss\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        lambda_coord = self.lambda_coord\n",
    "        lambda_noobj = self.lambda_noobj\n",
    "        \n",
    "        assert pred.shape == torch.Size((N, S, S, 5 * B + C))\n",
    "        assert target.shape == torch.Size((N, S, S, 5 + C))\n",
    "        \n",
    "        # flatten S x S grid into S^2\n",
    "        pred = pred.view(N, S**2, -1) # (N, S, S, 5 * B + C) -> (N, S^2, 5 * B + C)\n",
    "        target = target.view(N, S**2, -1) # (N, S, S, 5 + C) -> (N, S^2, 5 + C)\n",
    "        \n",
    "        print(\"flattening S x S to S^2\")\n",
    "        print(pred.shape, target.shape)\n",
    "        \n",
    "        # seperate tensor into box + classification\n",
    "        print(\"seperating tensor into box + classification\")\n",
    "        pred_bndboxes = pred[:, :, 0:5 * B] # (N, S^2, 5 * B + C) -> (N, S^2, 5 * B)\n",
    "        target_bndbox = target[:, :, 0:5] # (N, S^2, 5 + C) -> (N, S^2, 5)\n",
    "        \n",
    "        print(\"getting confidence\")\n",
    "        pred_confidences = pred_bndboxes[..., 0:-1:5] # (N, S^2, 5 * B) -> (N, S^2, B)\n",
    "        target_confidence = target_bndbox[..., 0] # (N, S^2, 5) -> (N, S^2)\n",
    "        \n",
    "        print(pred_confidences, pred_confidences.shape)\n",
    "        print(target_confidence, target_confidence.shape)\n",
    "        \n",
    "        print(\"getting bounding box\")\n",
    "        print(pred_bndboxes, pred_bndboxes.shape)\n",
    "        \n",
    "        box_indices = torch.arange(0, 5 * B) % 5 != 0 # mask for every 2nd, 3rd, 4th, and 5th element\n",
    "        pred_boxes = pred_bndboxes[..., box_indices] # (N, S^2, 5 * B) -> (N, S^2, 4 * B)\n",
    "        target_box = target_bndbox[:, :, 1: 5] # (N, S^2, 4)\n",
    "        \n",
    "        print(\"target bndbox\")\n",
    "        print(target_bndbox)\n",
    "        print(pred_boxes, target_box)\n",
    "        \n",
    "        \n",
    "        # print(pred_boxes, pred_boxes.shape)\n",
    "        # print(target_box, target_box.shape)\n",
    "        \n",
    "        print(\"getting classification\")\n",
    "        pred_classification = pred[:, :, 5 * B: 5 * B + C] # (N, S^2, 5 * B + C) -> (N, S^2, C)\n",
    "        target_classification = target[:, :, 5: 5 + C] # (N, S^2, 5 + C) -> (N, S^2, C)\n",
    "        \n",
    "        # print(pred_classification, pred_classification.shape)\n",
    "        # print(target_classification, target_classification.shape)\n",
    "        \n",
    "        # calculate IOU between predicted boxes and target box\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "f7f807c0-d2d9-4137-bce3-b1ba1b05b75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = 1\n",
    "B = 2\n",
    "C = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "id": "5ff89d04-7e88-46e6-b0c8-2ee1bef499c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 12])"
      ]
     },
     "execution_count": 353,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.zeros((S, S, 5 * B + C))\n",
    "pred[0, 0] = torch.tensor([1, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 1/7, 1/7, 0, 0.95])\n",
    "pred = pred.unsqueeze(0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "id": "9f00a0d5-e918-43be-8b0c-78bb6cd52ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 7])"
      ]
     },
     "execution_count": 354,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.zeros((S, S, 5 + C))\n",
    "target[0, 0] = torch.tensor([1, 0.5, 0.5, 1/7, 1/7, 0, 1])\n",
    "target = target.unsqueeze(0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "id": "2cf35d4a-707c-4974-88bd-e4d608aba49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv1Loss()"
      ]
     },
     "execution_count": 355,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_loss = YOLOv1Loss(\n",
    "    S=S,\n",
    "    B=B,\n",
    "    C=C\n",
    ")\n",
    "\n",
    "yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "id": "5d51aceb-f5f0-4e00-a3f8-cb02f4b9aa51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO LOSS\n",
      "flattening S x S to S^2\n",
      "torch.Size([1, 1, 12]) torch.Size([1, 1, 7])\n",
      "seperating tensor into box + classification\n",
      "getting confidence\n",
      "tensor([[[1., 1.]]]) torch.Size([1, 1, 2])\n",
      "tensor([[1.]]) torch.Size([1, 1])\n",
      "getting bounding box\n",
      "tensor([[[1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000,\n",
      "          0.1429, 0.1429]]]) torch.Size([1, 1, 10])\n",
      "target bndbox\n",
      "tensor([[[1.0000, 0.5000, 0.5000, 0.1429, 0.1429]]])\n",
      "tensor([[[0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.5000, 0.1429, 0.1429]]]) tensor([[[0.5000, 0.5000, 0.1429, 0.1429]]])\n",
      "getting classification\n"
     ]
    }
   ],
   "source": [
    "yolo_loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bfd1b-eef2-40f0-9ee3-08960244eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea89fc-642f-48da-9060-5485be1351a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d7c5c-8d51-4145-ab5a-a88bdff54451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fd91c87-c5c5-4145-bec2-d851c8dc328f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.zeros((1, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fbb13c25-896a-4cda-bd4c-3cf31a1f0776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape == torch.Size([1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58331274-33ca-42a2-9b1f-c72dd45c0129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7aae12-1e91-4380-97ef-8a62499c4469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce5561-e706-4781-b6b7-854f849503c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
