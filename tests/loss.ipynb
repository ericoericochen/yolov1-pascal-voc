{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b3655f03-1494-4678-9885-3e859882b97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "45d56b55-2a11-491f-b173-4deaf2a31472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataset\n",
    "from torchvision.ops import box_iou"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f9c8d69-fdcb-4cf5-8db6-954801fb9d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pascal_voc_train = torchvision.datasets.VOCDetection(\n",
    "    root=\"../data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"train\",\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d15f266e-7ac2-4b57-8e3f-146886742030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMING PASCAL VOC\n"
     ]
    }
   ],
   "source": [
    "voc_train = dataset.PascalVOC(pascal_voc=pascal_voc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "70f22340-8e61-4875-8f02-d13102365e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 701,
   "id": "864f6c31-62c8-40fc-b00f-4767443189d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YOLOv1Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLOv1 Loss\n",
    "    \"\"\"\n",
    "    def __init__(self, S=7, B=2, C=20, lambda_coord=5, lambda_noobj=0.5):\n",
    "        \"\"\"\n",
    "        S: dimension of the S x S grid\n",
    "        B: number of bounding boxes predicted by network\n",
    "        C: number of classes\n",
    "        lambda_coord: penalty for coord loss\n",
    "        lambda_noobj: penalty for confidence loss when no object is present in target\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        \n",
    "    def _xywh_to_x1y1x2y2(self, boxes: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Converts YOLO bounding box format to (x1, y1, x2, y2)\n",
    "        \n",
    "        pred: (N, S^2, X, 4)\n",
    "        \n",
    "        returns (N, S^2, X, 4)\n",
    "        \"\"\"\n",
    "        x = boxes[..., 0] # (N, S^2, X)\n",
    "        y = boxes[..., 1]\n",
    "        w = boxes[..., 2]\n",
    "        h = boxes[..., 3]\n",
    "        \n",
    "        # print(x, x.shape)\n",
    "        # print(y, y.shape)\n",
    "        # print(w, w.shape)\n",
    "        # print(h, h.shape)\n",
    "        \n",
    "        x1 = x - w / 2\n",
    "        y1 = y - h / 2\n",
    "        x2 = x + w / 2\n",
    "        y2 = y + h / 2\n",
    "        \n",
    "        # print(x1)\n",
    "        # print(y1)\n",
    "        # print(x2)\n",
    "        # print(y2)\n",
    "        \n",
    "        x1y1x2y2 = torch.stack((x1, y1, x2, y2), dim=3) # (N, S^2, X) -> (N, S^2, X, 4)\n",
    "        \n",
    "        # print(x1y1x2y2, x1y1x2y2.shape)\n",
    "        \n",
    "        return x1y1x2y2\n",
    "        \n",
    "    def _iou(self, pred, target) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Calculates the IOU between B prediction boxes and target boxe\n",
    "        \n",
    "        pred: (N, S^2, B, 4)\n",
    "        target: (N, S^2, 1, 4)\n",
    "        \n",
    "        returns (N, S^2, B)\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(\"CALCULATING IOUS\")\n",
    "        # sanity check to make sure tensors are of the right shape\n",
    "        assert len(pred) == len(target)\n",
    "        N = len(pred)\n",
    "        assert pred.shape == torch.Size((N, self.S**2, self.B, 4))\n",
    "        assert target.shape == torch.Size((N, self.S**2, 1, 4))\n",
    "        \n",
    "        # print(\"PASSED SANITY CHECKS\")\n",
    "        \n",
    "#         print(\"CONVERTING TO x1y1...\")\n",
    "        pred = self._xywh_to_x1y1x2y2(pred)\n",
    "        target = self._xywh_to_x1y1x2y2(target)\n",
    "        \n",
    "        # print(\"IOUS\")\n",
    "        # vectorized box ioi        \n",
    "        def _box_iou(pred, target):\n",
    "            print(pred[0].shape, target[0].shape)\n",
    "            pred = pred[0] # (B, 4)\n",
    "            target = target[0] # (1, 4)\n",
    "            \n",
    "            iou = box_iou(pred, target) # (B, 1)\n",
    "            iou = iou.unsqueeze(0) # (1, B, 1)\n",
    "            \n",
    "            # print(iou)\n",
    "            # print(iou.shape)\n",
    "            return iou\n",
    "        \n",
    "        v_box_iou = torch.vmap(_box_iou, in_dims=1, out_dims=1) # (N, S^2, B, 1)\n",
    "        \n",
    "        ious = v_box_iou(pred, target)\n",
    "        \n",
    "        # print(ious)\n",
    "        # print(ious.shape)\n",
    "        \n",
    "        ious = ious.squeeze(3) # (N, S^2, B, 1) -> (N, S^2, B)\n",
    "        \n",
    "        # print(ious, ious.shape)\n",
    "        \n",
    "        return ious\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred: (N x S x S x (5 * B + C))\n",
    "        target: (N x S x S x (5 + C))\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"YOLO LOSS\")\n",
    "        \n",
    "        # check pred and target are in the correct shape\n",
    "        assert len(pred) == len(target)\n",
    "        N = len(pred)\n",
    "        \n",
    "        # get parameters of YOLO loss\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        lambda_coord = self.lambda_coord\n",
    "        lambda_noobj = self.lambda_noobj\n",
    "        \n",
    "        assert pred.shape == torch.Size((N, S, S, 5 * B + C))\n",
    "        assert target.shape == torch.Size((N, S, S, 5 + C))\n",
    "        \n",
    "        # flatten S x S grid into S^2\n",
    "        pred = pred.view(N, S**2, -1) # (N, S, S, 5 * B + C) -> (N, S^2, 5 * B + C)\n",
    "        target = target.view(N, S**2, -1) # (N, S, S, 5 + C) -> (N, S^2, 5 + C)\n",
    "        \n",
    "        print(\"flattening S x S to S^2\")\n",
    "        print(pred.shape, target.shape)\n",
    "        \n",
    "        # seperate tensor into box + classification\n",
    "        print(\"seperating tensor into box + classification\")\n",
    "        pred_bndboxes = pred[:, :, 0:5 * B] # (N, S^2, 5 * B + C) -> (N, S^2, 5 * B)\n",
    "        target_bndbox = target[:, :, 0:5] # (N, S^2, 5 + C) -> (N, S^2, 5)\n",
    "        \n",
    "        print(\"getting confidence\")\n",
    "        pred_confidences = pred_bndboxes[..., 0:-1:5] # (N, S^2, 5 * B) -> (N, S^2, B)\n",
    "        target_confidence = target_bndbox[..., 0] # (N, S^2, 5) -> (N, S^2)\n",
    "        \n",
    "        print(pred_confidences, pred_confidences.shape)\n",
    "        print(target_confidence, target_confidence.shape)\n",
    "        \n",
    "        print(\"getting bounding box\")\n",
    "        print(pred_bndboxes, pred_bndboxes.shape)\n",
    "        \n",
    "        box_indices = torch.arange(0, 5 * B) % 5 != 0 # mask for every 2nd, 3rd, 4th, and 5th element\n",
    "        pred_boxes = pred_bndboxes[..., box_indices].view(N, S**2, -1, 4) # (N, S^2, 5 * B) -> (N, S^2, 4 * B) -> (N, S^2, B, 4)\n",
    "        target_box = target_bndbox[:, :, 1: 5].unsqueeze(2) # (N, S^2, 4)\n",
    "        \n",
    "        print(\"PRED BOXES\")\n",
    "        print(pred_boxes, pred_boxes.shape)\n",
    "        \n",
    "        print(\"TARGET BOX\")\n",
    "        print(target_box, target_box.shape)\n",
    "        \n",
    "        \n",
    "        print(\"getting classification\")\n",
    "        pred_classification = pred[:, :, 5 * B: 5 * B + C] # (N, S^2, 5 * B + C) -> (N, S^2, C)\n",
    "        target_classification = target[:, :, 5: 5 + C] # (N, S^2, 5 + C) -> (N, S^2, C)\n",
    "        \n",
    "        # print(pred_classification, pred_classification.shape)\n",
    "        # print(target_classification, target_classification.shape)\n",
    "        \n",
    "        # calculate IOU between predicted boxes and target box\n",
    "        ious = self._iou(pred_boxes, target_box)\n",
    "        \n",
    "        # get the max iou -> the box with the highest iou is the one responsible for\n",
    "        # predicting the bounding box in that given cell\n",
    "        \n",
    "        print(\"IOUS\")\n",
    "        print(ious, ious.shape)\n",
    "        \n",
    "        print(\"MAX IOUS\")\n",
    "        # (N, S^2, 1) ??\n",
    "        max_ious, indices = torch.max(ious, dim=2)\n",
    "        \n",
    "        print(max_ious, indices)\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 702,
   "id": "f7f807c0-d2d9-4137-bce3-b1ba1b05b75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# S = 1\n",
    "# B = 2\n",
    "# C = 2\n",
    "\n",
    "S = 2\n",
    "B = 2\n",
    "C = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 703,
   "id": "5ff89d04-7e88-46e6-b0c8-2ee1bef499c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 12])"
      ]
     },
     "execution_count": 703,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.zeros((S, S, 5 * B + C))\n",
    "pred[0, 0] = torch.tensor([1, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 1/7, 1/7, 0, 0.95])\n",
    "pred = pred.unsqueeze(0)\n",
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 704,
   "id": "9f00a0d5-e918-43be-8b0c-78bb6cd52ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2, 7])"
      ]
     },
     "execution_count": 704,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.zeros((S, S, 5 + C))\n",
    "target[0, 0] = torch.tensor([1, 0.5, 0.5, 1/7, 1/7, 0, 1])\n",
    "target = target.unsqueeze(0)\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 705,
   "id": "2cf35d4a-707c-4974-88bd-e4d608aba49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YOLOv1Loss()"
      ]
     },
     "execution_count": 705,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yolo_loss = YOLOv1Loss(\n",
    "    S=S,\n",
    "    B=B,\n",
    "    C=C\n",
    ")\n",
    "\n",
    "yolo_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 706,
   "id": "5d51aceb-f5f0-4e00-a3f8-cb02f4b9aa51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLO LOSS\n",
      "flattening S x S to S^2\n",
      "torch.Size([1, 4, 12]) torch.Size([1, 4, 7])\n",
      "seperating tensor into box + classification\n",
      "getting confidence\n",
      "tensor([[[1., 1.],\n",
      "         [0., 0.],\n",
      "         [0., 0.],\n",
      "         [0., 0.]]]) torch.Size([1, 4, 2])\n",
      "tensor([[1., 0., 0., 0.]]) torch.Size([1, 4])\n",
      "getting bounding box\n",
      "tensor([[[1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 1.0000, 0.5000, 0.5000,\n",
      "          0.1429, 0.1429],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000],\n",
      "         [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "          0.0000, 0.0000]]]) torch.Size([1, 4, 10])\n",
      "PRED BOXES\n",
      "tensor([[[[0.5000, 0.5000, 0.5000, 0.5000],\n",
      "          [0.5000, 0.5000, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000, 0.0000]]]]) torch.Size([1, 4, 2, 4])\n",
      "TARGET BOX\n",
      "tensor([[[[0.5000, 0.5000, 0.1429, 0.1429]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000, 0.0000]]]]) torch.Size([1, 4, 1, 4])\n",
      "getting classification\n",
      "torch.Size([2, 4]) torch.Size([1, 4])\n",
      "IOUS\n",
      "tensor([[[0.0816, 1.0000],\n",
      "         [   nan,    nan],\n",
      "         [   nan,    nan],\n",
      "         [   nan,    nan]]]) torch.Size([1, 4, 2])\n",
      "MAX IOUS\n",
      "tensor([[1., nan, nan, nan]]) tensor([[1, 0, 0, 0]])\n"
     ]
    }
   ],
   "source": [
    "yolo_loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bfd1b-eef2-40f0-9ee3-08960244eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea89fc-642f-48da-9060-5485be1351a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d7c5c-8d51-4145-ab5a-a88bdff54451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fd91c87-c5c5-4145-bec2-d851c8dc328f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.zeros((1, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fbb13c25-896a-4cda-bd4c-3cf31a1f0776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape == torch.Size([1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58331274-33ca-42a2-9b1f-c72dd45c0129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7aae12-1e91-4380-97ef-8a62499c4469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce5561-e706-4781-b6b7-854f849503c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
