{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3655f03-1494-4678-9885-3e859882b97e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "45d56b55-2a11-491f-b173-4deaf2a31472",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision.transforms import ToTensor, Resize, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "import dataset\n",
    "from torchvision.ops import box_iou\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6f9c8d69-fdcb-4cf5-8db6-954801fb9d05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pascal_voc_train = torchvision.datasets.VOCDetection(\n",
    "    root=\"../data\",\n",
    "    year=\"2007\",\n",
    "    image_set=\"train\",\n",
    "    download=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d15f266e-7ac2-4b57-8e3f-146886742030",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRANSFORMING PASCAL VOC\n"
     ]
    }
   ],
   "source": [
    "voc_train = dataset.PascalVOC(pascal_voc=pascal_voc_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70f22340-8e61-4875-8f02-d13102365e83",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def iou():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "864f6c31-62c8-40fc-b00f-4767443189d9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class YOLOv1Loss(nn.Module):\n",
    "    \"\"\"\n",
    "    YOLOv1 Loss\n",
    "    \"\"\"\n",
    "    def __init__(self, S=7, B=2, C=20, lambda_coord=5, lambda_noobj=0.5):\n",
    "        \"\"\"\n",
    "        S: dimension of the S x S grid\n",
    "        B: number of bounding boxes predicted by network\n",
    "        C: number of classes\n",
    "        lambda_coord: penalty for coord loss\n",
    "        lambda_noobj: penalty for confidence loss when no object is present in target\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        \n",
    "        self.S = S\n",
    "        self.B = B\n",
    "        self.C = C\n",
    "        self.lambda_coord = lambda_coord\n",
    "        self.lambda_noobj = lambda_noobj\n",
    "        \n",
    "    def xywh_to_x1y1x2y2(self, boxes: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Converts YOLO bounding box format to (x1, y1, x2, y2)\n",
    "        \n",
    "        pred: (X, 4)\n",
    "        \n",
    "        returns (X, 4)\n",
    "        \"\"\"\n",
    "        x = boxes[..., 0] # (N, S^2, X)\n",
    "        y = boxes[..., 1]\n",
    "        w = boxes[..., 2]\n",
    "        h = boxes[..., 3]\n",
    "        \n",
    "        x1 = x - w / 2\n",
    "        y1 = y - h / 2\n",
    "        x2 = x + w / 2\n",
    "        y2 = y + h / 2\n",
    "        \n",
    "        x1y1x2y2 = torch.stack((x1, y1, x2, y2), dim=1)\n",
    "        \n",
    "        return x1y1x2y2\n",
    "    \n",
    "    def forward(self, pred, target):\n",
    "        \"\"\"\n",
    "        pred: (N x S x S x (5 * B + C))\n",
    "        target: (N x S x S x (5 + C))\n",
    "        \"\"\"    \n",
    "        # check pred and target are in the correct shape\n",
    "        assert len(pred) == len(target)\n",
    "        N = len(pred)\n",
    "        \n",
    "        # get parameters of YOLO loss\n",
    "        S = self.S\n",
    "        B = self.B\n",
    "        C = self.C\n",
    "        lambda_coord = self.lambda_coord\n",
    "        lambda_noobj = self.lambda_noobj\n",
    "        \n",
    "        assert pred.shape == torch.Size((N, S, S, 5 * B + C))\n",
    "        assert target.shape == torch.Size((N, S, S, 5 + C))\n",
    "        \n",
    "        print(\"PRED SHAPE\")\n",
    "        print(pred.shape)\n",
    "        \n",
    "        print(\"TARGET SHAPE\")\n",
    "        print(target.shape)\n",
    "        \n",
    "        # obj, noobj mask: select bounding boxes whose target bounding box has a confidence=1 for obj and confidence=0\n",
    "        # for noobj\n",
    "        obj_mask = target[:, :, :, 0] == 1\n",
    "        noobj_mask = target[:, :, :, 0] == 0\n",
    "        \n",
    "        # select predictions and targets where ground truth contains an object\n",
    "        obj_pred = pred[obj_mask] # (num_obj, 5*B+C)\n",
    "        obj_target = target[obj_mask] # (num_obj, 5+C)\n",
    "        \n",
    "        print(\"OBJ PRED + TARGET\")\n",
    "        print(obj_pred, obj_pred.shape)\n",
    "        print(obj_target, obj_target.shape)\n",
    "        \n",
    "        # get bounding boxes\n",
    "        obj_pred_bndbox = obj_pred[:, :5*B].view(-1, B, 5) # (num_obj, 5*B+C) -> (num_obj, B, 5)\n",
    "        obj_target_bndbox = obj_target[:, :5].view(-1, 1, 5) # (num_obj, 5*B+C) -> (num_obj, 1, 5)\n",
    "        \n",
    "        print(\"OBJ PRED BNDBOX\")\n",
    "        print(obj_pred_bndbox, obj_pred_bndbox.shape)\n",
    "        print(obj_target_bndbox, obj_target_bndbox.shape)\n",
    "        \n",
    "        # calculate ious\n",
    "        max_iou_mask = torch.BoolTensor(obj_pred_bndbox.size())\n",
    "        \n",
    "        print(max_iou_mask, max_iou_mask.shape)\n",
    "        \n",
    "        print(\"CALCULATING IOUS\")\n",
    "        for i in range(obj_pred_bndbox.size(0)):\n",
    "            pred_bndbox = obj_pred_bndbox[i][:, 1:] # (B, 4)\n",
    "            target_bndbox = obj_target_bndbox[i][:, 1:] # (1, 4)\n",
    "            print(pred_bndbox, target_bndbox)\n",
    "            \n",
    "            pred_bndbox = self.xywh_to_x1y1x2y2(pred_bndbox)\n",
    "            target_bndbox = self.xywh_to_x1y1x2y2(target_bndbox)\n",
    "            \n",
    "            print(pred_bndbox)\n",
    "            print(target_bndbox)\n",
    "        \n",
    "            ious = box_iou(pred_bndbox, target_bndbox).squeeze(-1) # (B)\n",
    "            \n",
    "            print(\"IOUS\")\n",
    "            print(ious)\n",
    "            \n",
    "            max_iou, max_idx = ious.max(dim=0)\n",
    "            \n",
    "            print(max_iou, max_idx)\n",
    "        \n",
    "            max_iou_mask[i, max_idx] = 1\n",
    "        \n",
    "        print(max_iou_mask)\n",
    "        \n",
    "        # responsible predictors\n",
    "        obj_pred_bndbox = obj_pred_bndbox[max_iou_mask].view(-1, 5) # (num_obj, 5)\n",
    "        \n",
    "        print(obj_pred_bndbox)\n",
    "        \n",
    "     \n",
    "        ###\n",
    "        # Bounding Box Error\n",
    "        ###\n",
    "        print(\"BOUNDING BOX ERROR\")\n",
    "        pred_xy = obj_pred_bndbox[:, 1:3]\n",
    "        target_xy = obj_target_bndbox.squeeze(1)[:, 1:3]\n",
    "        print(pred_xy, target_xy)\n",
    "        \n",
    "        print(target_xy)\n",
    "        \n",
    "        xy_loss = lambda_coord * F.mse_loss(pred_xy, target_xy, reduction=\"sum\")\n",
    "          \n",
    "        print(xy_loss)\n",
    "        \n",
    "        print(\"WH\")\n",
    "        pred_wh = torch.sqrt(obj_pred_bndbox[:, 3:5])\n",
    "        target_wh = torch.sqrt(obj_target_bndbox.squeeze(1)[:, 3:5])\n",
    "        \n",
    "        print(pred_wh, target_wh)\n",
    "        \n",
    "        wh_loss = lambda_coord * F.mse_loss(pred_wh, target_wh, reduction=\"sum\")\n",
    "        \n",
    "        print(wh_loss)\n",
    "        \n",
    "        obj_pred_confidence = obj_pred_bndbox[:, 0]\n",
    "        obj_target_confidence = obj_target_bndbox.squeeze(1)[:, 0]\n",
    "        \n",
    "        \n",
    "        print(\"OBJ confidence\")\n",
    "        print(obj_pred_confidence, obj_target_confidence)\n",
    "        \n",
    "        obj_confidence_loss = F.mse_loss(obj_pred_confidence, obj_target_confidence)\n",
    "        print(obj_confidence_loss)\n",
    "        \n",
    "        ###\n",
    "        # Confidence Error\n",
    "        ###\n",
    "        \n",
    "        \n",
    "        ###\n",
    "        # Classification Error\n",
    "        ###\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "f7f807c0-d2d9-4137-bce3-b1ba1b05b75a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "S = 1\n",
    "B = 2\n",
    "C = 2\n",
    "\n",
    "# S = 2\n",
    "# B = 2\n",
    "# C = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "5ff89d04-7e88-46e6-b0c8-2ee1bef499c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 12])"
      ]
     },
     "execution_count": 283,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = torch.zeros((S, S, 5 * B + C))\n",
    "pred[0, 0] = torch.tensor([1, 0.5, 0.5, 0.5, 0.5, 0.95, 0.5, 0.5, 1/7, 1/7, 0, 0.95])\n",
    "pred = pred.unsqueeze(0)\n",
    "pred.shape\n",
    "\n",
    "# pred = torch.zeros((2, S, S, 5 * B + C))\n",
    "# pred[0, 0, 0] = torch.tensor([1, 0.5, 0.5, 0.5, 0.5, 1, 0.5, 0.5, 1/7, 1/7, 0, 0.95])\n",
    "# pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "9f00a0d5-e918-43be-8b0c-78bb6cd52ac3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 1, 7])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = torch.zeros((S, S, 5 + C))\n",
    "target[0, 0] = torch.tensor([1, 0.5, 0.5, 1/7, 1/7, 0, 1])\n",
    "target = target.unsqueeze(0)\n",
    "target.shape\n",
    "\n",
    "# target = torch.zeros((2, S, S, 5 + C))\n",
    "# target[0, 0, 0] = torch.tensor([1, 0.5, 0.5, 1/7, 1/7, 0, 1])\n",
    "# target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "2cf35d4a-707c-4974-88bd-e4d608aba49b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRED SHAPE\n",
      "torch.Size([1, 1, 1, 12])\n",
      "TARGET SHAPE\n",
      "torch.Size([1, 1, 1, 7])\n",
      "OBJ PRED + TARGET\n",
      "tensor([[1.0000, 0.5000, 0.5000, 0.5000, 0.5000, 0.9500, 0.5000, 0.5000, 0.1429,\n",
      "         0.1429, 0.0000, 0.9500]]) torch.Size([1, 12])\n",
      "tensor([[1.0000, 0.5000, 0.5000, 0.1429, 0.1429, 0.0000, 1.0000]]) torch.Size([1, 7])\n",
      "OBJ PRED BNDBOX\n",
      "tensor([[[1.0000, 0.5000, 0.5000, 0.5000, 0.5000],\n",
      "         [0.9500, 0.5000, 0.5000, 0.1429, 0.1429]]]) torch.Size([1, 2, 5])\n",
      "tensor([[[1.0000, 0.5000, 0.5000, 0.1429, 0.1429]]]) torch.Size([1, 1, 5])\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [False, False, False, False, False]]]) torch.Size([1, 2, 5])\n",
      "CALCULATING IOUS\n",
      "tensor([[0.5000, 0.5000, 0.5000, 0.5000],\n",
      "        [0.5000, 0.5000, 0.1429, 0.1429]]) tensor([[0.5000, 0.5000, 0.1429, 0.1429]])\n",
      "tensor([[0.2500, 0.2500, 0.7500, 0.7500],\n",
      "        [0.4286, 0.4286, 0.5714, 0.5714]])\n",
      "tensor([[0.4286, 0.4286, 0.5714, 0.5714]])\n",
      "IOUS\n",
      "tensor([0.0816, 1.0000])\n",
      "tensor(1.) tensor(1)\n",
      "tensor([[[False, False, False, False, False],\n",
      "         [ True,  True,  True,  True,  True]]])\n",
      "tensor([[0.9500, 0.5000, 0.5000, 0.1429, 0.1429]])\n",
      "BOUNDING BOX ERROR\n",
      "tensor([[0.5000, 0.5000]]) tensor([[0.5000, 0.5000]])\n",
      "tensor([[0.5000, 0.5000]])\n",
      "tensor(0.)\n",
      "WH\n",
      "tensor([[0.3780, 0.3780]]) tensor([[0.3780, 0.3780]])\n",
      "tensor(0.)\n",
      "OBJ confidence\n",
      "tensor([0.9500]) tensor([1.])\n",
      "tensor(0.0025)\n"
     ]
    }
   ],
   "source": [
    "yolo_loss = YOLOv1Loss(\n",
    "    S=S,\n",
    "    B=B,\n",
    "    C=C\n",
    ")\n",
    "\n",
    "yolo_loss(pred, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d51aceb-f5f0-4e00-a3f8-cb02f4b9aa51",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b9bfd1b-eef2-40f0-9ee3-08960244eda5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ea89fc-642f-48da-9060-5485be1351a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64d7c5c-8d51-4145-ab5a-a88bdff54451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "8fd91c87-c5c5-4145-bec2-d851c8dc328f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "a = torch.zeros((1, 2, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "fbb13c25-896a-4cda-bd4c-3cf31a1f0776",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape == torch.Size([1, 2, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "58331274-33ca-42a2-9b1f-c72dd45c0129",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2, 2])"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7aae12-1e91-4380-97ef-8a62499c4469",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ce5561-e706-4781-b6b7-854f849503c0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
